---
title: Viva Glint’s position on expected response rates
description: The response rate for recurring surveys is a percentage calculation of the number of people who completed the survey, divided by the number of people who received the survey invitation.
ms.author: SarahBerg
author: SarahAnneBerg
manager: pamgreen
audience: admin
f1.keywords: NOCSH
keywords: Response rate setup, comments
ms.collection: 
 - M365initiative-viva
 - selfserve
search-appverid: MET150
ms.topic: article
ms.service: viva
localization_priority: high pri
ms.date: 04/28/2023
--- 

# Viva Glint’s position on expected response rates

Expect the unexpected! Response rates differ between surveys, industries, and populations. They can be filtered by teams, locations, or any demographic cut you've supplied in your Employee Attribute File.

- **For recurring and ad hoc surveys** : The response rate is a percentage calculation of the number of people who completed the survey, divided by the number of people who received the survey invitation.
- **For Employee Lifecycle surveys** : The response rate is a percentage calculation of the number of people who completed the survey, divided by the number of people who received the survey invitation. Unlike recurring and ad-hoc surveys, the response rate may change depending on the date range selected in the report. When selecting a date range, the response rate will include people who responded to surveys generated during that period.
- **For Always-On surveys** : Because the survey is always live, the response rate can't be calculated in the same manner. In this case, the response rate percentage refers to the number of participants who submitted the survey, divided by the total number of eligible participants who started the survey.

>[!CAUTION]
> Comparators are never apples to apples. For this reason, Viva Glint discourages placing too much value on them. Because many companies like to see response rate benchmarks, Viva Glint provides them below for informational purposes only.

## The response rate benchmark score used on the platform

The benchmark score of 75% displayed on the platform reflects Glint's latest global industry update on engagement from June 2022.

If you require a deeper dive:

This table uses the mean (average) response rate and is suggested for use as your primary metric:

| **Program** | **2021** | **2020** | **2019** |
| --- | --- | --- | --- |
| Engagement (recurring survey) | 75%\* | 76% | 80%\* |
| Onboarding (Employee Lifecycle survey) | 42% | 45% | NA |
| Exit (Employee Lifecycle survey) | 50% | 48% | NA |

\* Ongoing stressors introduced by the pandemic, alongside a potentially fickle workforce looking for change have likely driven the 5% change in response rate.

For more context, you can refer to the median response rate to consider trends:

| **Program** | **2021** | **2020** | **2019** |
| --- | --- | --- | --- |
| Engagement (recurring survey) | 77% | 79% | 79% |
| Onboarding (Employee Lifecycle survey) | 43% | 46% | 48% |
| Exit (Employee Lifecycle survey) | 53% | 47% | 51% |

### Is my response rate high enough to be considered representative?

For organizations of 1000 employees, once a representative sample of data from 50% of the organization is collected, we can say with 95% (+/- 3%) confidence that the score reported on the sample is within 3% of the true score (the score we would get if the entire population responded).

Most of our customers have more than 1000 employees. For these companies, when responses reach or go above 60%, we typically don't see company-wide scores change by more than a point or two at higher response levels.

Sample size varies. The most important factor in judging the sample's quality isn't its size but how similar it's to the population of interest. For example, a random sample of 100 out of a company's full 2000-employee population will be much more informative than a sample of the 200 out of 2000 who work in Human Resources.

### What percentage of respondents leave at least one comment?

Across all Glint survey cycles completed in 2022, 57% of respondents left at least one comment and this didn't change from 2021. 29% of the comments were prescriptive in nature, which is up 2 pts since 2021.

### Which of the core engagement items has the largest percentage of comments? Which has the least?

**eSat** has the largest percentage of comments among the core Engagement items.

**Role** continues to have the smallest percentage of comments.

**Resources** has the highest percentage of prescriptive comments.

**Care** has the least number of comments.

### Does favorability affect frequency of comments?

Across all core items, 1.7% of favorable respondents left a comment, while 4.7% of neutral respondents and 9.4% of unfavorable respondents did. What does this mean?

**Negative** responders are more likely to leave a comment compared to **favorable** responders.

## Related articles

- [Use the Response Rate report](https://go.microsoft.com/fwlink/?linkid=2231209)
- [Internal benchmark comparisons](https://go.microsoft.com/fwlink/?linkid=2230868)