---
title: Choose your comparison data for Viva Glint reporting
description: Choosing the right comparison data when setting up feedback reporting sets the right context for understanding strengths and opportunities.
ms.author: SarahBerg
author: SarahAnneBerg
manager: pamgreen
audience: admin
f1.keywords: NOCSH
keywords: Benchmarks, global benchmark, internal benchmark, external benchmark, survey comparators, My Teams, Average Question
ms.collection: 
 - M365initiative-viva
 - selfserve
search-appverid: MET150
ms.topic: article
ms.service: viva
localization_priority: high pri
ms.date: 04/28/2023
---

# Choose your comparison data for Viva Glint reporting

Choosing the right comparison data when considering survey results sets the right context for understanding strengths and opportunities and make the difference between effective progress and misdirected actions. Good comparison choices are crucial, so managers need to be certain to find the right comparison for understanding their engagement feedback.

Comparisons come from these sources:

- Internal: Compared to your organization's overall scores or another internal group such as Division or Business Unit
- Historical: Compared to previous survey results
- External: Compared to external benchmarks comprised of scores across Viva Glint customers

Use a combination of comparative data to reveal the most comprehensive information for your managers.

## How to change the comparison in a report

The company admin chooses the default comparison for survey data. Managers can choose a different comparison group to provide additional context for your survey scores.

1. Select the **Settings** button.
2. Use the down-facing arrow next to **Comparison** to select a different comparator.
3. Select **Done**.

## Four comparison settings are available in reporting

Viva Glint provides four options for comparison reporting by default. In addition to the following four settings, your company may have one or more internal comparisons configured (for example, Division or Business Unit).

- **Benchmark**  – Provides a comparison point for feedback based on survey data compiled from all Viva Glint customers. Helpful for admins and first-time survey results analysis.
- **Company**  – Displays team scores in comparison to company-wide scores for the same questions. Helpful for users with more than one area of responsibility
- **My Teams** – Compares a manager's team score to an overall score derived from a filter. This setting is the superset of access and is best used with custom access or managers with large organizations
- **Average Question** - Presents a single, overall score for all questions and respondents within your access. Helpful for users looking for some level of variance in their score.

## Understand why having comparison choices is beneficial

**Comparison scores within the Viva Glint platform enable you to make sense of your results.** Without meaningful comparison data, inaccurate conclusions may cause you to focus on the wrong areas for improvement.

**Algorithms built into the platform take comparative data sets into consideration**. Our platform intelligently highlights Strengths and Opportunities by considering a combination of survey results, their impact on the outcomes you care about (for example, engagement), and where you stand on available comparisons.

**Comparisons between groups within an organization may be helpful in score interpretation.** If there are certain groups that typically score higher relative to other groups on a set of priority questions, it may be useful to source best practices from that group and share them with other groups to support broad scale improvement.

## Determine which comparison data to use

Consider your company's overall business and measurement strategy, including where you are in your survey cycle (for example, first survey, subsequent surveys, etc.) to decide which comparison data will be the most useful. In general, we believe that external benchmarks can provide some useful level-setting comparisons during an initial survey, but they aren't nearly as useful to the organization as internal and trend (historical) comparisons in subsequent surveys.

### When is the external benchmark comparison useful?

For an initial survey, when no historical data exists, most organizations are interested in seeing how their scores compare to an _external_ benchmark, to begin orienting themselves to their results. Glint has more than 180 survey questions with benchmark data by industry, function, and country.

External benchmarks are helpful initially, but as you begin to survey more frequently, trends and internal comparisons become more useful for making incremental improvements in areas that matter most to teams.

The external benchmark is useful for company admins to provide a meaningful reference point in assessing an organization's overall scores, however individual managers shouldn't heavily focus on the external benchmark. For them, the internal comparison and their own team's past survey scores are better comparisons.

> [!TIP]
> Use [Viva Glint's global benchmark offerings and methodology](https://community.glintinc.com/survey-science-55/benchmarks-glint-s-global-benchmark-offerings-and-methodology-1611) for external benchmarking comparisons.

### When is the total company or other internal comparison useful?

For managers, we recommend utilizing the internal comparison. This is most often your organization's total company scores, however, your company may have additional internal comparisons set up (for example, Division or Business Unit) that may be more meaningful. The internal comparison provides a more relevant comparison point for managers than the external benchmark.

In addition, after your first survey, we recommend managers pay attention to their team's trend (change in scores) over time to see where progress is being made and where there are opportunities to improve or course correct.

For Employee Lifecycle surveys, we recommend using internal comparisons given the uniqueness of employee experiences by organization, although we do also have external benchmarks for our standard onboarding and exit items.

### When is the My Teams comparison useful?

The My Teams comparison represents the scores for the user's total access within Viva Glint. For Company admins, the My Teams comparison will be the same as the Company comparison since they have access to the total company data. For a manager, My Teams will represent the scores for everyone who reports up through them (their roll-up organization).

> [!NOTE]
> If no filter is applied to your report, the My Teams comparison will be the same as your overall scores and will show no differences. For the My Teams comparison to be useful, you would want to be looking at filtered data (for example, subteams within the hierarchy, specific attribute groups, etc.)

The My Teams comparison tends to be most useful for higher level managers or those who oversee large organizations.

### When is the Average Question comparison useful?

Use the Average Question comparison under these circumstances:

- For any survey when there's no available comparisons (such as trend or external benchmark)
- For any survey where the difference between your score and others is small, such as versus Company Overall

In these instances, the Average Question score allows a comparison measurement that highlights the highest and lowest scoring items, which can be used as a launching point for conversation and choosing focus areas.

### Tips for choosing comparisons successfully

- **Don't rely on external benchmarks indefinitely.** For some leaders, it's critical to understand how similar organizations are scoring across the question set to help them decide where to prioritize actions to deliver the same or better employee experience. Viva Glint recommends that, eventually, you focus on internal comparisons over external benchmarks to address your organization's unique strengths and opportunities for improvement in the context of business goals and priorities.
- **Learn how to interpret differences in scores.** To determine where to take action, it's important to understand the magnitude of positive or negative differences between your scores and other comparison scores.
- **Caution small team managers on using external benchmarks as comparisons.** Benchmark data represents an average of millions of data points and is meant to be used for assessing organization overall scores. A better comparison for first-line managers is past survey scores (trend) for their own team or organization averages.

## People Science recommendations around choosing comparators

Read this People Science explained article for a deep dive into choosing comparators.

### Keep in mind

When comparing two groups, a group against a benchmark, or a score change over time, consider both practical and statistical significance.

- Practical significance: The difference in the scores between two groups that is large enough to observe unique patterns of working and behaving between the two groups. If a score difference between two teams is too small to detect any material difference, that difference may not carry as much practical significance.
- Statistical significance: The probability that the difference between the scores of two groups isn't chance or coincidence, but accurately represents the unique responses of individuals in each group. This becomes useful with larger groups, where it can be used to surface reliable patterns in data. On your platform, Alerts and Driver Impact analyses automatically check for statistical significance and displays only statistically significant results.

> [!NOTE]
> Your company may have substituted custom terms for the Viva Glint terminology explained in this article.